{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import gym\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from Agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"LunarLander-v2\"\n",
    "TRAIN_ITERATIONS = 5000\n",
    "MAX_EPISODE_LENGTH = 1000\n",
    "TRAJECTORY_BUFFER_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "RENDER_EVERY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vinay Patel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "state_input (InputLayer)     [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "actor_output_layer (Dense)   (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,377\n",
      "Trainable params: 1,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "state_input (InputLayer)        [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32)           288         state_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32)           1056        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "advantage_input (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "old_prediction_input (InputLaye [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "actor_output_layer (Dense)      (None, 4)            132         dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,476\n",
      "Trainable params: 1,476\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "state_input (InputLayer)        [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32)           288         state_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32)           1056        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "advantage_input (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "old_prediction_input (InputLaye [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "actor_output_layer (Dense)      (None, 4)            132         dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,476\n",
      "Trainable params: 1,476\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "agent = Agent(env.action_space.n,env.observation_space.shape,BATCH_SIZE)\n",
    "samples_filled = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vinay Patel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Episode:0, step:119, r_sum:-1.4466337157971005\n",
      "Episode:1, step:127, r_sum:-2.046024993085439\n",
      "Episode:2, step:108, r_sum:-2.353856031324444\n",
      "Episode:3, step:117, r_sum:-1.9526772181287124\n",
      "Episode:4, step:111, r_sum:-2.786514242680675\n",
      "Episode:5, step:74, r_sum:-0.6866498084107646\n",
      "Episode:6, step:115, r_sum:-1.2257962727122318\n",
      "Episode:7, step:91, r_sum:-0.8946908507790972\n",
      "Episode:8, step:147, r_sum:-4.362923503233551\n",
      "Episode:9, step:93, r_sum:-3.079414020304766\n",
      "Episode:10, step:122, r_sum:-3.599357419894774\n",
      "Episode:11, step:116, r_sum:-4.800566549186621\n",
      "Episode:12, step:133, r_sum:-1.4045805253068044\n",
      "Episode:13, step:142, r_sum:-2.8044430842217785\n",
      "Episode:14, step:83, r_sum:-1.4372715896920512\n",
      "Episode:15, step:89, r_sum:-2.9023790433889394\n",
      "Episode:16, step:85, r_sum:-3.079899378789998\n",
      "Episode:17, step:83, r_sum:-1.8948227878053467\n",
      "Episode:18, step:83, r_sum:-0.8338270428640191\n",
      "Episode:19, step:116, r_sum:-3.4205371188436122\n",
      "Episode:20, step:111, r_sum:-4.518649207945531\n",
      "Episode:21, step:91, r_sum:-4.034933597349307\n",
      "Episode:22, step:56, r_sum:-0.6622322122964124\n",
      "Episode:23, step:90, r_sum:-0.5725134055776044\n",
      "Episode:24, step:72, r_sum:-0.6676061042408576\n",
      "Episode:25, step:92, r_sum:-2.2927377719264914\n",
      "Episode:26, step:108, r_sum:-1.6158250751707395\n",
      "Episode:27, step:129, r_sum:-0.194759012465052\n",
      "Episode:28, step:95, r_sum:-0.5668065363184049\n",
      "Episode:29, step:105, r_sum:-4.768028292004178\n",
      "Episode:30, step:62, r_sum:-1.0629257559151457\n",
      "Episode:31, step:65, r_sum:-0.7895807100654556\n",
      "Episode:32, step:83, r_sum:-1.197213549535984\n",
      "Episode:33, step:62, r_sum:-1.0935844198799625\n",
      "Episode:34, step:80, r_sum:-1.4097563270278186\n",
      "Episode:35, step:115, r_sum:-1.7394219273432276\n",
      "Episode:36, step:202, r_sum:-0.7813092713658029\n",
      "Episode:37, step:91, r_sum:-2.7203813248950333\n",
      "Episode:38, step:86, r_sum:-2.1796833173393777\n",
      "Episode:39, step:141, r_sum:-1.4395575857815817\n",
      "Episode:40, step:60, r_sum:-1.1290979876683482\n",
      "Episode:41, step:113, r_sum:-2.4622660563634895\n",
      "Episode:42, step:111, r_sum:-0.6370570232285974\n",
      "Episode:43, step:73, r_sum:-1.7914286785538214\n",
      "Episode:44, step:70, r_sum:-0.00818083875611575\n",
      "Episode:45, step:165, r_sum:-2.258053628410005\n",
      "Episode:46, step:97, r_sum:-2.5347784844322367\n",
      "Episode:47, step:118, r_sum:-1.5805329493838451\n",
      "Episode:48, step:72, r_sum:-1.2976834127278845\n",
      "Episode:49, step:118, r_sum:-1.0511239732582702\n",
      "Episode:50, step:108, r_sum:-1.8844132648640768\n",
      "Episode:51, step:167, r_sum:-3.140678735080219\n",
      "Episode:52, step:90, r_sum:-1.458030655797801\n",
      "Episode:53, step:127, r_sum:-2.2783686443552984\n",
      "Episode:54, step:105, r_sum:-1.2116041620072648\n",
      "Episode:55, step:82, r_sum:-0.6586073208448946\n",
      "Episode:56, step:156, r_sum:-0.4109872102133363\n",
      "Episode:57, step:74, r_sum:-1.157319361233096\n",
      "Episode:58, step:106, r_sum:-2.141864035841299\n",
      "Episode:59, step:113, r_sum:0.22404688267849737\n",
      "Episode:60, step:80, r_sum:-2.172681456699342\n",
      "Episode:61, step:65, r_sum:-0.6465515411270821\n",
      "Episode:62, step:90, r_sum:-1.2517877944739686\n",
      "Episode:63, step:135, r_sum:-2.58747330141326\n",
      "Episode:64, step:96, r_sum:-1.6666867520781303\n",
      "Episode:65, step:95, r_sum:-1.517847226805849\n",
      "Episode:66, step:95, r_sum:-1.1791085350375416\n",
      "Episode:67, step:64, r_sum:0.295176400788848\n",
      "Episode:68, step:112, r_sum:-1.5230297573285094\n",
      "Episode:69, step:85, r_sum:-3.4496091715048753\n",
      "Episode:70, step:71, r_sum:-1.0656934476077913\n",
      "Episode:71, step:71, r_sum:-0.6817372448756206\n",
      "Episode:72, step:113, r_sum:-3.0141503276503725\n",
      "Episode:73, step:156, r_sum:-2.22494883222722\n",
      "Episode:74, step:57, r_sum:-1.816934727182442\n",
      "Episode:75, step:102, r_sum:-0.07423329902182707\n",
      "Episode:76, step:103, r_sum:-0.18277679842819394\n",
      "Episode:77, step:100, r_sum:-1.771947059789529\n",
      "Episode:78, step:103, r_sum:-1.2235497379526297\n",
      "Episode:79, step:131, r_sum:-1.4312897066622345\n",
      "Episode:80, step:105, r_sum:-1.878692983685915\n",
      "Episode:81, step:76, r_sum:-0.6580940615710406\n",
      "Episode:82, step:78, r_sum:-1.3718320758850635\n",
      "Episode:83, step:125, r_sum:-1.278632102957289\n",
      "Episode:84, step:77, r_sum:-1.047932967515668\n",
      "Episode:85, step:68, r_sum:-1.0171968842231323\n",
      "Episode:86, step:98, r_sum:-2.4459524576336613\n",
      "Episode:87, step:63, r_sum:-1.3887366363211484\n",
      "Episode:88, step:83, r_sum:-1.3515713075362012\n",
      "Episode:89, step:83, r_sum:-1.112852030921875\n",
      "Episode:90, step:69, r_sum:-1.5382251967896194\n",
      "Episode:91, step:55, r_sum:-1.3078861926091738\n",
      "Episode:92, step:83, r_sum:-1.4219432119636697\n",
      "Episode:93, step:97, r_sum:-1.0836286515481843\n",
      "Episode:94, step:115, r_sum:-1.924507267007999\n",
      "Episode:95, step:91, r_sum:-1.388659976377569\n",
      "Episode:96, step:100, r_sum:-0.9905458043583141\n",
      "Episode:97, step:96, r_sum:-1.2571087310976\n",
      "Episode:98, step:219, r_sum:-2.8507103600237986\n",
      "Episode:99, step:91, r_sum:-1.5599124321119058\n",
      "Episode:100, step:85, r_sum:-0.7838097301520692\n",
      "Episode:101, step:140, r_sum:-1.9937289997234977\n"
     ]
    }
   ],
   "source": [
    "for cnt_episode in range(TRAIN_ITERATIONS):\n",
    "        s = env.reset()\n",
    "        r_sum = 0\n",
    "        for cnt_step in range(MAX_EPISODE_LENGTH):\n",
    "            #sometimes render\n",
    "            if cnt_episode % RENDER_EVERY == 0 :\n",
    "                env.render()\n",
    "            #get action from agent given state\n",
    "            a = agent.choose_action(s)\n",
    "            #get s_,r,done\n",
    "            s_, r, done, _ = env.step(a)\n",
    "            r /= 100\n",
    "            r_sum += r\n",
    "            if done:\n",
    "                r = -1\n",
    "            #store transitions to agent.memory\n",
    "            agent.store_transition(s, a, s_, r, done)\n",
    "            samples_filled += 1\n",
    "            #train in batches one buffer is filled with samples.\n",
    "            if samples_filled % TRAJECTORY_BUFFER_SIZE == 0 and samples_filled != 0:\n",
    "                #To be sample efficient, sample as often as statistically necearry to\n",
    "                # use all availible samples in memory. Imortant to sample randomly\n",
    "                # to keep the training data independant and identically distributed IID\n",
    "                for _ in range(TRAJECTORY_BUFFER_SIZE // BATCH_SIZE):\n",
    "                    agent.train_network()\n",
    "                agent.memory.clear()\n",
    "                samples_filled = 0\n",
    "            #set state to next_state\n",
    "            s = s_\n",
    "            if done:\n",
    "                break\n",
    "        if cnt_episode % 1 == 0:\n",
    "            print(f\"Episode:{cnt_episode}, step:{cnt_step}, r_sum:{r_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
